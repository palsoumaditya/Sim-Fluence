#!/usr/bin/env python3
"""
Validation script for existing SimFluence AI model
Checks if the current model and data work properly
"""

import os
import sys
import pandas as pd

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))


def validate_model_files():
    """Check if required model files exist"""
    print("üîç Validating Model Files...")

    required_files = [
        'models/likes_predictor.pkl',
        'data/simfluence_reddit_training.csv',
        'src/preprocess.py',
        'src/train_model.py',
        'src/predict.py'
    ]

    missing_files = []
    for file_path in required_files:
        full_path = file_path
        if not os.path.exists(full_path):
            missing_files.append(file_path)
        else:
            print(f"   ‚úÖ {file_path}")

    if missing_files:
        print(f"   ‚ùå Missing files: {missing_files}")
        return False

    return True


def validate_data_format():
    """Check if training data has the expected format"""
    print("\nüìä Validating Data Format...")

    try:
        csv_path = os.path.join('data', 'simfluence_reddit_training.csv')
        df = pd.read_csv(csv_path)

        print(f"   üìà Dataset shape: {df.shape}")
        print(f"   üìã Columns: {list(df.columns)}")

        # Check for required columns
        required_columns = [
            'receivedLikes', 'receivedComments', 'length', 'containsImage',
            'dayOfWeek', 'postTimeOfDay', 'topCommentSentiment'
        ]

        missing_cols = [
            col for col in required_columns if col not in df.columns]
        if missing_cols:
            print(f"   ‚ùå Missing columns: {missing_cols}")
            return False

        print("   ‚úÖ All required columns present")

        # Check data types
        print(f"   üìä Sample data:")
        # Convert to numeric for range calculation
        likes_numeric = pd.to_numeric(df['receivedLikes'], errors='coerce')
        comments_numeric = pd.to_numeric(df['receivedComments'], errors='coerce')
        length_numeric = pd.to_numeric(df['length'], errors='coerce')
        
        print(f"      Likes range: {likes_numeric.min():.0f} - {likes_numeric.max():.0f}")
        print(f"      Comments range: {comments_numeric.min():.0f} - {comments_numeric.max():.0f}")
        print(f"      Length range: {length_numeric.min():.0f} - {length_numeric.max():.0f}")

        return True

    except Exception as e:
        print(f"   ‚ùå Error reading data: {str(e)}")
        return False


def validate_preprocessing():
    """Test the preprocessing function"""
    print("\n‚öôÔ∏è Validating Preprocessing...")

    try:
        from src.preprocess import load_and_preprocess_data

        csv_path = os.path.join('data', 'simfluence_reddit_training.csv')
        df, feature_columns = load_and_preprocess_data(csv_path)
        
        # Split the data manually for validation
        from sklearn.model_selection import train_test_split
        X = df[feature_columns]
        y = df['receivedLikes']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        print(f"   üìä Training set shape: {X_train.shape}")
        print(f"   üìä Test set shape: {X_test.shape}")
        print(f"   üè∑Ô∏è Number of features: {len(feature_columns)}")
        print(f"   üìã Feature columns: {feature_columns[:5]}..." if len(
            feature_columns) > 5 else f"   üìã Feature columns: {feature_columns}")

        # Check for any NaN values
        if X_train.isna().sum().sum() > 0:
            print(f"   ‚ö†Ô∏è Warning: NaN values found in training data")
        else:
            print("   ‚úÖ No NaN values in training data")

        return True

    except Exception as e:
        print(f"   ‚ùå Error in preprocessing: {str(e)}")
        return False


def validate_model_loading():
    """Test model loading and prediction"""
    print("\nü§ñ Validating Model Loading...")

    try:
        from src.predict import load_model, predict_likes

        # Test model loading
        model, feature_columns = load_model()
        print(f"   ‚úÖ Model loaded successfully")
        print(f"   üè∑Ô∏è Expected features: {len(feature_columns)}")

        # Test prediction with sample data
        sample_input = {
            "length": 35,
            "containsImage": 1,
            "userFollowers": 1200,
            "userKarma": 4500,
            "accountAgeDays": 700,
            "avgEngagementRate": 0.06,
            "avgLikes": 20,
            "avgComments": 5,
            "shouldImprove": 0,
            "dayOfWeek_Monday": 0,
            "dayOfWeek_Tuesday": 0,
            "dayOfWeek_Wednesday": 0,
            "dayOfWeek_Thursday": 0,
            "dayOfWeek_Friday": 1,
            "dayOfWeek_Saturday": 0,
            "postTimeOfDay_Evening": 1,
            "postTimeOfDay_Morning": 0,
            "postTimeOfDay_Afternoon": 0,
            "topCommentSentiment_Neutral": 0,
            "topCommentSentiment_Positive": 1
        }

        prediction = predict_likes(sample_input)
        print(f"   üîÆ Sample prediction: {prediction:.1f} likes")

        if 0 <= prediction <= 10000:  # Reasonable range
            print("   ‚úÖ Prediction in reasonable range")
        else:
            print(f"   ‚ö†Ô∏è Warning: Prediction seems unusual: {prediction}")

        return True

    except Exception as e:
        print(f"   ‚ùå Error in model loading/prediction: {str(e)}")
        return False


def validate_training():
    """Test model training process"""
    print("\nüèãÔ∏è Validating Training Process...")

    try:
        # Import training function
        sys.path.append('src')
        from train_model import train_and_save_model

        print("   ‚úÖ Training module imported successfully")
        print("   üí° Note: Run 'python src/train_model.py' to retrain the model")

        return True

    except Exception as e:
        print(f"   ‚ùå Error in training validation: {str(e)}")
        return False


def main():
    """Run all validation tests"""
    print("üß™ SimFluence AI Model Validation")
    print("=" * 50)

    os.chdir(os.path.dirname(os.path.abspath(__file__)))

    tests = [
        validate_model_files,
        validate_data_format,
        validate_preprocessing,
        validate_model_loading,
        validate_training
    ]

    passed = 0
    total = len(tests)

    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"   ‚ùå Test failed with exception: {str(e)}")

    print("\n" + "=" * 50)
    print(f"üéØ Validation Results: {passed}/{total} tests passed")

    if passed == total:
        print("‚úÖ All validations passed! Your AI model is ready to use.")
        print("\nüöÄ Next steps:")
        print("   1. Start the AI API: python api/app.py")
        print("   2. Test the API: python test/test_api.py")
        print("   3. Integrate with your backend using the integration guide")
    else:
        print("‚ùå Some validations failed. Please check the errors above.")
        print("\nüîß Troubleshooting:")
        print("   1. Make sure you have the training data in data/simfluence_reddit_training.csv")
        print("   2. Run 'python src/train_model.py' to train the model")
        print("   3. Install requirements: pip install -r requirements.txt")


if __name__ == "__main__":
    main()
